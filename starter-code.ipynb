{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e043b2",
   "metadata": {},
   "source": [
    "## Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "One way to define the data science process is as follows:\n",
    "\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. \n",
    "\n",
    "---\n",
    "## Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8225250-f77c-4bd4-957e-2d4aa5ab6983",
   "metadata": {},
   "source": [
    "- Does personality type correlate with handedness\n",
    "- Is there a correlation between handedness and gender identity\n",
    "- How do gender and handedness interact to influence personality traits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32144652",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### Read in the file titled \"data.csv\":\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a154e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e730059",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df = pd.read_csv('data.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614c76a7-c206-4b11-be04-08530fd43e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  country  fromgoogle  engnat  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1  ...       US           2       1   \n",
       "1   1   5   1   4   2   5   5   4   1    5  ...       CA           2       1   \n",
       "2   1   2   1   1   5   4   3   2   1    4  ...       NL           2       2   \n",
       "3   1   4   1   5   1   4   5   4   3    5  ...       US           2       1   \n",
       "4   5   1   5   1   5   1   5   1   3    1  ...       US           2       1   \n",
       "\n",
       "   age  education  gender  orientation  race  religion  hand  \n",
       "0   22          3       1            1     3         2     3  \n",
       "1   14          1       2            2     6         1     1  \n",
       "2   30          4       1            1     1         1     2  \n",
       "3   18          2       2            5     3         2     2  \n",
       "4   22          3       1            1     3         2     3  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review sample rows\n",
    "quiz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980e3463-4a8c-47c1-bd3a-5ff0325cedb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1              int64\n",
       "Q2              int64\n",
       "Q3              int64\n",
       "Q4              int64\n",
       "Q5              int64\n",
       "Q6              int64\n",
       "Q7              int64\n",
       "Q8              int64\n",
       "Q9              int64\n",
       "Q10             int64\n",
       "Q11             int64\n",
       "Q12             int64\n",
       "Q13             int64\n",
       "Q14             int64\n",
       "Q15             int64\n",
       "Q16             int64\n",
       "Q17             int64\n",
       "Q18             int64\n",
       "Q19             int64\n",
       "Q20             int64\n",
       "Q21             int64\n",
       "Q22             int64\n",
       "Q23             int64\n",
       "Q24             int64\n",
       "Q25             int64\n",
       "Q26             int64\n",
       "Q27             int64\n",
       "Q28             int64\n",
       "Q29             int64\n",
       "Q30             int64\n",
       "Q31             int64\n",
       "Q32             int64\n",
       "Q33             int64\n",
       "Q34             int64\n",
       "Q35             int64\n",
       "Q36             int64\n",
       "Q37             int64\n",
       "Q38             int64\n",
       "Q39             int64\n",
       "Q40             int64\n",
       "Q41             int64\n",
       "Q42             int64\n",
       "Q43             int64\n",
       "Q44             int64\n",
       "introelapse     int64\n",
       "testelapse      int64\n",
       "country        object\n",
       "fromgoogle      int64\n",
       "engnat          int64\n",
       "age             int64\n",
       "education       int64\n",
       "gender          int64\n",
       "orientation     int64\n",
       "race            int64\n",
       "religion        int64\n",
       "hand            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecad882-f610-4388-8552-0436a8cee582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1             0\n",
       "Q2             0\n",
       "Q3             0\n",
       "Q4             0\n",
       "Q5             0\n",
       "Q6             0\n",
       "Q7             0\n",
       "Q8             0\n",
       "Q9             0\n",
       "Q10            0\n",
       "Q11            0\n",
       "Q12            0\n",
       "Q13            0\n",
       "Q14            0\n",
       "Q15            0\n",
       "Q16            0\n",
       "Q17            0\n",
       "Q18            0\n",
       "Q19            0\n",
       "Q20            0\n",
       "Q21            0\n",
       "Q22            0\n",
       "Q23            0\n",
       "Q24            0\n",
       "Q25            0\n",
       "Q26            0\n",
       "Q27            0\n",
       "Q28            0\n",
       "Q29            0\n",
       "Q30            0\n",
       "Q31            0\n",
       "Q32            0\n",
       "Q33            0\n",
       "Q34            0\n",
       "Q35            0\n",
       "Q36            0\n",
       "Q37            0\n",
       "Q38            0\n",
       "Q39            0\n",
       "Q40            0\n",
       "Q41            0\n",
       "Q42            0\n",
       "Q43            0\n",
       "Q44            0\n",
       "introelapse    0\n",
       "testelapse     0\n",
       "country        0\n",
       "fromgoogle     0\n",
       "engnat         0\n",
       "age            0\n",
       "education      0\n",
       "gender         0\n",
       "orientation    0\n",
       "race           0\n",
       "religion       0\n",
       "hand           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "quiz_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f55bfe1-6fac-4e7b-a3cb-79abc77eab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.962715</td>\n",
       "      <td>3.829589</td>\n",
       "      <td>2.846558</td>\n",
       "      <td>3.186902</td>\n",
       "      <td>2.865440</td>\n",
       "      <td>3.672084</td>\n",
       "      <td>3.216539</td>\n",
       "      <td>3.184512</td>\n",
       "      <td>2.761233</td>\n",
       "      <td>3.522945</td>\n",
       "      <td>...</td>\n",
       "      <td>479.994503</td>\n",
       "      <td>1.576243</td>\n",
       "      <td>1.239962</td>\n",
       "      <td>30.370698</td>\n",
       "      <td>2.317878</td>\n",
       "      <td>1.654398</td>\n",
       "      <td>1.833413</td>\n",
       "      <td>5.013623</td>\n",
       "      <td>2.394359</td>\n",
       "      <td>1.190966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.360291</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>1.664804</td>\n",
       "      <td>1.476879</td>\n",
       "      <td>1.545798</td>\n",
       "      <td>1.342238</td>\n",
       "      <td>1.490733</td>\n",
       "      <td>1.387382</td>\n",
       "      <td>1.511805</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>...</td>\n",
       "      <td>3142.178542</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.440882</td>\n",
       "      <td>367.201726</td>\n",
       "      <td>0.874264</td>\n",
       "      <td>0.640915</td>\n",
       "      <td>1.303454</td>\n",
       "      <td>1.970996</td>\n",
       "      <td>2.184164</td>\n",
       "      <td>0.495357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>324.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>119834.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23763.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Q1           Q2           Q3           Q4           Q5  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      1.962715     3.829589     2.846558     3.186902     2.865440   \n",
       "std       1.360291     1.551683     1.664804     1.476879     1.545798   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     3.000000     1.000000     2.000000     1.000000   \n",
       "50%       1.000000     5.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.000000     5.000000     5.000000     5.000000     4.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "                Q6           Q7           Q8           Q9          Q10  ...  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000  ...   \n",
       "mean      3.672084     3.216539     3.184512     2.761233     3.522945  ...   \n",
       "std       1.342238     1.490733     1.387382     1.511805     1.242890  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       3.000000     2.000000     2.000000     1.000000     3.000000  ...   \n",
       "50%       4.000000     3.000000     3.000000     3.000000     4.000000  ...   \n",
       "75%       5.000000     5.000000     4.000000     4.000000     5.000000  ...   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000  ...   \n",
       "\n",
       "          testelapse   fromgoogle       engnat           age    education  \\\n",
       "count    4184.000000  4184.000000  4184.000000   4184.000000  4184.000000   \n",
       "mean      479.994503     1.576243     1.239962     30.370698     2.317878   \n",
       "std      3142.178542     0.494212     0.440882    367.201726     0.874264   \n",
       "min         7.000000     1.000000     0.000000     13.000000     0.000000   \n",
       "25%       186.000000     1.000000     1.000000     18.000000     2.000000   \n",
       "50%       242.000000     2.000000     1.000000     21.000000     2.000000   \n",
       "75%       324.250000     2.000000     1.000000     27.000000     3.000000   \n",
       "max    119834.000000     2.000000     2.000000  23763.000000     4.000000   \n",
       "\n",
       "            gender  orientation         race     religion         hand  \n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000  \n",
       "mean      1.654398     1.833413     5.013623     2.394359     1.190966  \n",
       "std       0.640915     1.303454     1.970996     2.184164     0.495357  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     1.000000     5.000000     1.000000     1.000000  \n",
       "50%       2.000000     1.000000     6.000000     2.000000     1.000000  \n",
       "75%       2.000000     2.000000     6.000000     2.000000     1.000000  \n",
       "max       3.000000     5.000000     7.000000     7.000000     3.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review value\n",
    "quiz_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b55b21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### Conduct background research:\n",
    "\n",
    "Domain knowledge is irreplaceable. Figuring out what information is relevant to a problem, or what data would be useful to gather, is a major part of any end-to-end data science project! For this lab, you'll be using a dataset that someone else has put together, rather than collecting the data yourself.\n",
    "\n",
    "Do some background research about personality and handedness. What features, if any, are likely to help you make good predictions? How well do you think you'll be able to model this? Write a few bullet points summarizing what you believe, and remember to cite external sources.\n",
    "\n",
    "You don't have to be exhaustive here. Do enough research to form an opinion, and then move on.\n",
    "\n",
    "> You'll be using the answers to Q1-Q44 for modeling; you can disregard other features, e.g. country, age, internet browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d76881-b94a-4610-ab71-2b3c4315601e",
   "metadata": {},
   "source": [
    "> A comparison of the personality characteristics of 34 left-handed and 148 right-handed students (aged 17â€“22 yrs) suggested that handedness may be related to extraversion for females: Left-handed females were less extraverted than right-handed females.\n",
    "\n",
    "[Reference](https://www.researchgate.net/publication/232519132_The_relationship_between_handedness_and_personality_traits_Extraversion_and_neuroticism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf0649",
   "metadata": {},
   "source": [
    "### Conduct exploratory data analysis on this dataset:\n",
    "\n",
    "If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process.\n",
    "\n",
    "You might use this section to perform data cleaning if you find it to be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff31c6e5-b87c-482d-9e04-f7f8a2fdefea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3803, 56)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove Q1-Q44 with zero value\n",
    "quiz_df = quiz_df[~(quiz_df.loc[:, 'Q1':'Q44'] == 0).any(axis=1)]\n",
    "quiz_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38eb9e15-4446-4b79-bc4a-6ee1a26b148f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3794, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove hand with zero value\n",
    "quiz_df = quiz_df[quiz_df['hand'] != 0]\n",
    "quiz_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dfaf7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.00000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "      <td>3794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.971798</td>\n",
       "      <td>3.838166</td>\n",
       "      <td>2.844228</td>\n",
       "      <td>3.206115</td>\n",
       "      <td>2.885345</td>\n",
       "      <td>3.682130</td>\n",
       "      <td>3.222457</td>\n",
       "      <td>3.196363</td>\n",
       "      <td>2.768318</td>\n",
       "      <td>3.518450</td>\n",
       "      <td>...</td>\n",
       "      <td>446.395888</td>\n",
       "      <td>1.577227</td>\n",
       "      <td>1.243279</td>\n",
       "      <td>24.629678</td>\n",
       "      <td>2.32077</td>\n",
       "      <td>1.654454</td>\n",
       "      <td>1.835793</td>\n",
       "      <td>5.009752</td>\n",
       "      <td>2.387190</td>\n",
       "      <td>1.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.365267</td>\n",
       "      <td>1.540441</td>\n",
       "      <td>1.661345</td>\n",
       "      <td>1.464837</td>\n",
       "      <td>1.539970</td>\n",
       "      <td>1.330714</td>\n",
       "      <td>1.481074</td>\n",
       "      <td>1.380508</td>\n",
       "      <td>1.500097</td>\n",
       "      <td>1.226434</td>\n",
       "      <td>...</td>\n",
       "      <td>2574.865462</td>\n",
       "      <td>0.494065</td>\n",
       "      <td>0.441832</td>\n",
       "      <td>12.448414</td>\n",
       "      <td>0.87479</td>\n",
       "      <td>0.640901</td>\n",
       "      <td>1.303092</td>\n",
       "      <td>1.971096</td>\n",
       "      <td>2.182681</td>\n",
       "      <td>0.489974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>93888.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Q1           Q2           Q3           Q4           Q5  \\\n",
       "count  3794.000000  3794.000000  3794.000000  3794.000000  3794.000000   \n",
       "mean      1.971798     3.838166     2.844228     3.206115     2.885345   \n",
       "std       1.365267     1.540441     1.661345     1.464837     1.539970   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       1.000000     3.000000     1.000000     2.000000     1.000000   \n",
       "50%       1.000000     5.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.000000     5.000000     5.000000     5.000000     4.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "                Q6           Q7           Q8           Q9          Q10  ...  \\\n",
       "count  3794.000000  3794.000000  3794.000000  3794.000000  3794.000000  ...   \n",
       "mean      3.682130     3.222457     3.196363     2.768318     3.518450  ...   \n",
       "std       1.330714     1.481074     1.380508     1.500097     1.226434  ...   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "25%       3.000000     2.000000     2.000000     1.000000     3.000000  ...   \n",
       "50%       4.000000     3.000000     3.000000     3.000000     4.000000  ...   \n",
       "75%       5.000000     5.000000     4.000000     4.000000     5.000000  ...   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000  ...   \n",
       "\n",
       "         testelapse   fromgoogle       engnat          age   education  \\\n",
       "count   3794.000000  3794.000000  3794.000000  3794.000000  3794.00000   \n",
       "mean     446.395888     1.577227     1.243279    24.629678     2.32077   \n",
       "std     2574.865462     0.494065     0.441832    12.448414     0.87479   \n",
       "min       41.000000     1.000000     0.000000    13.000000     0.00000   \n",
       "25%      187.000000     1.000000     1.000000    18.000000     2.00000   \n",
       "50%      243.000000     2.000000     1.000000    21.000000     2.00000   \n",
       "75%      325.000000     2.000000     1.000000    27.000000     3.00000   \n",
       "max    93888.000000     2.000000     2.000000   409.000000     4.00000   \n",
       "\n",
       "            gender  orientation         race     religion         hand  \n",
       "count  3794.000000  3794.000000  3794.000000  3794.000000  3794.000000  \n",
       "mean      1.654454     1.835793     5.009752     2.387190     1.190300  \n",
       "std       0.640901     1.303092     1.971096     2.182681     0.489974  \n",
       "min       0.000000     0.000000     0.000000     0.000000     1.000000  \n",
       "25%       1.000000     1.000000     5.250000     1.000000     1.000000  \n",
       "50%       2.000000     1.000000     6.000000     2.000000     1.000000  \n",
       "75%       2.000000     2.000000     6.000000     2.000000     1.000000  \n",
       "max       3.000000     5.000000     7.000000     7.000000     3.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26e657",
   "metadata": {},
   "source": [
    "### Calculate and interpret the baseline accuracy rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89ecc3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hand\n",
       "1    85.27\n",
       "2    10.44\n",
       "3     4.30\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_df['hand'].value_counts(normalize=True).mul(100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016bb4e",
   "metadata": {},
   "source": [
    "### Short answer questions:\n",
    "\n",
    "In this lab, you'll use K-nearest neighbors and logistic regression to model handedness based on psychological factors. \n",
    "\n",
    "Answer the following related questions; your answers may be in bullet points.\n",
    "\n",
    "#### Describe the difference between regression and classification problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463a005-f86f-4aae-b91c-af1079703377",
   "metadata": {},
   "source": [
    "###### Regression\n",
    " - Predicts a continuous numerical value\n",
    "\n",
    "###### Classification\n",
    " - Predicts a categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7469aee",
   "metadata": {},
   "source": [
    "#### Considering $k$-nearest neighbors, describe the relationship between $k$ and the bias-variance tradeoff:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37fb4df-a533-464d-8049-7e2322216d5a",
   "metadata": {},
   "source": [
    "###### K increase\n",
    "- Bias increases\n",
    "- Variance decreases\n",
    "\n",
    "###### K decrease\n",
    "- Bias decreases\n",
    "- Variance increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc66d6",
   "metadata": {},
   "source": [
    "#### Why do we often standardize predictor variables when using $k$-nearest neighbors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c94b627-9a2d-4ef7-b542-10cb5609aa52",
   "metadata": {},
   "source": [
    "Standardization ensures that all features contribute equally to the distance calculation by transforming them to a common scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad52536",
   "metadata": {},
   "source": [
    "#### Do you think we should standardize the explanatory variables for this problem? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef2822-e87c-40b3-9aaf-7de8e50dc0b4",
   "metadata": {},
   "source": [
    "No scaling required as all explanatory variables share a common range of 1-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6e09f",
   "metadata": {},
   "source": [
    "#### How do we settle on $k$ for a $k$-nearest neighbors model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7e27e-6f9c-425f-8518-6c63ce7086e4",
   "metadata": {},
   "source": [
    "- Create a grid of possible k values.\n",
    "- Train the model for each combination of hyperparameters (including k) and evaluate its performance.\n",
    "- Select the combination with the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fe4a8",
   "metadata": {},
   "source": [
    "#### What is the default type of regularization for logistic regression as implemented in scikit-learn? (You might [check the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477d79d-ce62-4b84-9e62-6ed486a0668f",
   "metadata": {},
   "source": [
    "- L2 (Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b117e3",
   "metadata": {},
   "source": [
    "#### Describe the relationship between the scikit-learn `LogisticRegression` argument `C` and regularization strength:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687a9b4f-1a68-44e2-8584-6b5b8024b9bf",
   "metadata": {},
   "source": [
    "Inverse of regularization strength, smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19a574",
   "metadata": {},
   "source": [
    "#### Describe the relationship between regularization strength and the bias-variance tradeoff:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3536cb-cb80-4ae5-a10a-96c2ddb2e240",
   "metadata": {},
   "source": [
    "##### Low Regularization Strength\n",
    "- High Variance, Low Bias\n",
    "##### High Regularization Strength\n",
    "- High Bias, Low Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7089674d",
   "metadata": {},
   "source": [
    "#### Logistic regression is considered more interpretable than $k$-nearest neighbors. Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111040e-3f20-40ff-ba04-3d7c6cdca8cc",
   "metadata": {},
   "source": [
    "- Logistic regression models provide coefficients for each feature\n",
    "- Logistic regression provides a global view of how features contribute to the prediction\n",
    "- Logistic regression can provide some local explanations for individual predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00360fc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 & 5 Modeling: $k$-nearest neighbors\n",
    "\n",
    "### Train-test split your data:\n",
    "\n",
    "Your features should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7239cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f'Q{i}' for i in range(1, 45)]\n",
    "X = quiz_df[features]\n",
    "y = quiz_df['hand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f7e27",
   "metadata": {},
   "source": [
    "#### Create and fit four separate $k$-nearest neighbors models: \n",
    "- one with $k = 3$\n",
    "- one with $k = 5$\n",
    "- one with $k = 15$\n",
    "- one with $k = 25$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d154750-7c9a-4e0b-95a1-24e086cf8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cresate a KNN score test function\n",
    "def knn_test(n, X_train, y_train, X_test, y_test):\n",
    "    # innitialize models\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_preds = knn.predict(X_test)\n",
    "\n",
    "    # compare cross validation scores\n",
    "    print(f\"Cross validation score for KNN k={n} is {cross_val_score(knn, X_train, y_train, cv=5).mean():.8f}\")\n",
    "    print(f\"Score of training for KNN k={n} is {knn.score(X_train, y_train):.8f}\")\n",
    "    print(f\"Score of testing for KNN k={n} is {knn.score(X_test, y_test):.8f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d00f5835-b296-4c3f-b0bb-a854c6fc7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for KNN k=3 is 0.82075783\n",
      "Score of training for KNN k=3 is 0.86952224\n",
      "Score of testing for KNN k=3 is 0.82608696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K=3\n",
    "knn_test(3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5373c211-e646-4d6d-bcd4-08963cac5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for KNN k=5 is 0.83855025\n",
      "Score of training for KNN k=5 is 0.85304778\n",
      "Score of testing for KNN k=5 is 0.84453228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K=5\n",
    "knn_test(5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0184d17f-f8e4-48e7-8c42-f2b1add6f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for KNN k=15 is 0.85271829\n",
      "Score of training for KNN k=15 is 0.85271829\n",
      "Score of testing for KNN k=15 is 0.85243742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K=15\n",
    "knn_test(15, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d48ac1b8-9a1f-473d-83ac-ad03c1942b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for KNN k=25 is 0.85271829\n",
      "Score of training for KNN k=25 is 0.85271829\n",
      "Score of testing for KNN k=25 is 0.85243742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K=25\n",
    "knn_test(25, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6f202",
   "metadata": {},
   "source": [
    "### Evaluate your models:\n",
    "\n",
    "Evaluate each of your four models on the training and testing sets, and interpret the four scores. \n",
    "\n",
    "Are any of your models overfit or underfit? \n",
    "\n",
    "Do any of your models beat the baseline accuracy rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee6be4-71c8-457a-a496-b897441073ee",
   "metadata": {},
   "source": [
    "- All models exhibit overfitting, as evidenced by significantly higher training scores than testing scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba7153-2d39-477f-975b-a6317403c088",
   "metadata": {},
   "source": [
    "- None of the models outperform the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488dc25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 & 5 Modeling: logistic regression\n",
    "\n",
    "#### Create and fit four separate logistic regression models: one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "Note: You can use the same train and test data as used above with kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe96a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cresate a LogisticRegression score test function\n",
    "def lgr_test(algo, alpha, X_train, y_train, X_test, y_test):\n",
    "    # initialize models\n",
    "    if algo == 'lasso':\n",
    "        penalty = 'l1'\n",
    "    elif algo == 'ridge':\n",
    "        penalty = 'l2'\n",
    "    else:\n",
    "        return\n",
    "    lgr = LogisticRegression(C=1/alpha, penalty=penalty, solver='liblinear')\n",
    "    lgr.fit(X_train, y_train)\n",
    "    y_preds = lgr.predict(X_test)\n",
    "\n",
    "    # compare cross validation scores\n",
    "    print(f\"Cross validation score for LogisticRegression alpha={alpha}, penalty={algo} is {cross_val_score(lgr, X_train, y_train, cv=5).mean():.8f}\")\n",
    "    print(f\"Score of training for LogisticRegression alpha={alpha}, penalty={algo} is {lgr.score(X_train, y_train):.8f}\")\n",
    "    print(f\"Score of testing for LogisticRegression alpha={alpha}, penalty={algo} is {lgr.score(X_test, y_test):.8f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38b52db5-8655-4016-bed5-aae65dacd2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for LogisticRegression alpha=1, penalty=lasso is 0.85271829\n",
      "Score of training for LogisticRegression alpha=1, penalty=lasso is 0.85271829\n",
      "Score of testing for LogisticRegression alpha=1, penalty=lasso is 0.85243742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso, alpha 1\n",
    "lgr_test('lasso', 1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf77910e-94a5-46c9-b1eb-7cfd9eeb4602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for LogisticRegression alpha=10, penalty=lasso is 0.85271829\n",
      "Score of training for LogisticRegression alpha=10, penalty=lasso is 0.85271829\n",
      "Score of testing for LogisticRegression alpha=10, penalty=lasso is 0.85243742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso, alpha 10\n",
    "lgr_test('lasso', 10, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b9738e3-5752-4255-bed2-e1ee2de75078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for LogisticRegression alpha=1, penalty=ridge is 0.85271829\n",
      "Score of training for LogisticRegression alpha=1, penalty=ridge is 0.85271829\n",
      "Score of testing for LogisticRegression alpha=1, penalty=ridge is 0.85243742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge, alpha 1\n",
    "lgr_test('ridge', 1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc6f495a-e920-49fc-ae4b-5a488431fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for LogisticRegression alpha=10, penalty=ridge is 0.85271829\n",
      "Score of training for LogisticRegression alpha=10, penalty=ridge is 0.85271829\n",
      "Score of testing for LogisticRegression alpha=10, penalty=ridge is 0.85243742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge, alpha 10\n",
    "lgr_test('ridge', 10, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703eecea",
   "metadata": {},
   "source": [
    "### Evaluate your models:\n",
    "\n",
    "Evaluate each of your four models on the training and testing sets, and interpret the four scores. \n",
    "\n",
    "Are any of your models overfit or underfit? \n",
    "\n",
    "Do any of your models beat the baseline accuracy rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb6058-9478-45e2-9fa9-b9cbc2c391c0",
   "metadata": {},
   "source": [
    "- None of them are overfit or underfit, score is very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101add5-cf94-4b4f-aa02-388d67281566",
   "metadata": {},
   "source": [
    "- All models accuracy are quite same as the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a746e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "Are any of your models worth moving forward with? \n",
    "\n",
    "What are the \"best\" models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004d2fd-cd15-432e-9c86-159087dc565a",
   "metadata": {},
   "source": [
    "- None of the models achieve acceptable accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
